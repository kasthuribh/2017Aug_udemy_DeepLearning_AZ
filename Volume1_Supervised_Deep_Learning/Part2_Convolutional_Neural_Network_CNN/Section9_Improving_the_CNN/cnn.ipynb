{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#folder structure\n",
    "#dataset\n",
    "    #test_set\n",
    "        #cats\n",
    "        #dogs\n",
    "    #train_set\n",
    "        #cats\n",
    "        #dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width,img_height=64,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(p,input_shape=(32,32,3)):\n",
    "    # Initialising the CNN\n",
    "    classifier = Sequential()\n",
    "    #Convolution + Pooling Layer\n",
    "    classifier.add(Convolution2D(filters=32,kernel_size=(3,3), padding=\"same\" , input_shape=input_shape, activation='relu' ))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #Convolution + Pooling Layer\n",
    "    classifier.add(Convolution2D(filters=32,kernel_size=(3,3), padding=\"same\" ,  activation='relu' ))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #Convolution + Pooling Layer\n",
    "    classifier.add(Convolution2D(filters=64,kernel_size=(3,3), padding=\"same\" , activation='relu' ))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #Convolution + Pooling Layer\n",
    "    classifier.add(Convolution2D(filters=64,kernel_size=(3,3), padding=\"same\" , activation='relu' ))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    #Flattening \n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    #Fully Connection\n",
    "    classifier.add(Dense(units=64, activation='relu' ))\n",
    "    classifier.add(Dropout(p))\n",
    "    classifier.add(Dense(units=64, activation='relu' ))\n",
    "    classifier.add(Dropout(p/2))\n",
    "    classifier.add(Dense(units=64, activation='relu' ))\n",
    "    #output layer\n",
    "    classifier.add(Dense(units=1, activation='sigmoid' ))\n",
    "    \n",
    "    # Compiling the CNN\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    metrics=['accuracy']\n",
    "    classifier.compile(optimizer=optimizer, loss='binary_crossentropy' , metrics=metrics)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(batch_size=32,epochs=10):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(img_width, img_height),  #dimension expected by CNN\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  #binary or more than 2\n",
    "\n",
    "    test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    classifier=create_model(p=0.6,input_shape=(img_width,image_height,3))\n",
    "    classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000/batch_size, \n",
    "        epochs=epochs,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000/batch_size,\n",
    "        workers=12,\n",
    "        max_q_size=100\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloudera/virtualenv/python27/lib/python2.7/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., workers=12, validation_data=<keras.pre..., steps_per_epoch=250, epochs=100, max_queue_size=100, validation_steps=62)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 39s - loss: 0.6941 - acc: 0.4859 - val_loss: 0.6931 - val_acc: 0.5010\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 36s - loss: 0.6934 - acc: 0.4964 - val_loss: 0.6931 - val_acc: 0.5071\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 37s - loss: 0.6924 - acc: 0.5115 - val_loss: 0.6856 - val_acc: 0.5432\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 36s - loss: 0.6935 - acc: 0.5042 - val_loss: 0.6930 - val_acc: 0.5020\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 36s - loss: 0.6931 - acc: 0.5217 - val_loss: 0.6889 - val_acc: 0.5737\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 36s - loss: 0.6844 - acc: 0.5581 - val_loss: 0.6824 - val_acc: 0.5462\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 36s - loss: 0.6635 - acc: 0.5964 - val_loss: 0.6374 - val_acc: 0.6408\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 37s - loss: 0.6440 - acc: 0.6370 - val_loss: 0.6254 - val_acc: 0.6611\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 36s - loss: 0.6135 - acc: 0.6691 - val_loss: 0.5751 - val_acc: 0.7167\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 36s - loss: 0.5947 - acc: 0.6892 - val_loss: 0.5607 - val_acc: 0.7231\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 35s - loss: 0.5631 - acc: 0.7140 - val_loss: 0.5571 - val_acc: 0.7093\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 35s - loss: 0.5375 - acc: 0.7316 - val_loss: 0.5208 - val_acc: 0.7551\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 35s - loss: 0.5237 - acc: 0.7484 - val_loss: 0.4971 - val_acc: 0.7683\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 35s - loss: 0.5056 - acc: 0.7536 - val_loss: 0.4906 - val_acc: 0.7805\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 35s - loss: 0.4983 - acc: 0.7659 - val_loss: 0.4798 - val_acc: 0.7764\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 35s - loss: 0.4970 - acc: 0.7610 - val_loss: 0.4933 - val_acc: 0.7769\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 35s - loss: 0.4712 - acc: 0.7823 - val_loss: 0.4614 - val_acc: 0.7812\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 36s - loss: 0.4809 - acc: 0.7744 - val_loss: 0.4523 - val_acc: 0.8018\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 35s - loss: 0.4650 - acc: 0.7842 - val_loss: 0.4539 - val_acc: 0.7851\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 35s - loss: 0.4539 - acc: 0.7910 - val_loss: 0.4348 - val_acc: 0.8049\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 35s - loss: 0.4486 - acc: 0.7908 - val_loss: 0.4349 - val_acc: 0.7917\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 35s - loss: 0.4542 - acc: 0.7884 - val_loss: 0.4322 - val_acc: 0.7973\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 35s - loss: 0.4428 - acc: 0.7985 - val_loss: 0.4615 - val_acc: 0.7688\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 35s - loss: 0.4346 - acc: 0.7988 - val_loss: 0.4302 - val_acc: 0.7901\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 35s - loss: 0.4299 - acc: 0.8080 - val_loss: 0.4355 - val_acc: 0.8130\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 35s - loss: 0.4240 - acc: 0.8055 - val_loss: 0.4255 - val_acc: 0.8018\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 35s - loss: 0.4249 - acc: 0.8073 - val_loss: 0.4259 - val_acc: 0.8181\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 35s - loss: 0.4107 - acc: 0.8125 - val_loss: 0.4078 - val_acc: 0.8196\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 35s - loss: 0.4054 - acc: 0.8176 - val_loss: 0.3964 - val_acc: 0.8303\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 35s - loss: 0.4085 - acc: 0.8175 - val_loss: 0.4091 - val_acc: 0.8140\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 35s - loss: 0.3971 - acc: 0.8254 - val_loss: 0.3956 - val_acc: 0.8232\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 35s - loss: 0.3977 - acc: 0.8217 - val_loss: 0.4023 - val_acc: 0.8130\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 35s - loss: 0.3848 - acc: 0.8326 - val_loss: 0.3918 - val_acc: 0.8277\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 36s - loss: 0.3848 - acc: 0.8276 - val_loss: 0.3800 - val_acc: 0.8272\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 35s - loss: 0.3862 - acc: 0.8291 - val_loss: 0.4373 - val_acc: 0.7927\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 36s - loss: 0.3763 - acc: 0.8339 - val_loss: 0.3854 - val_acc: 0.8333\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 35s - loss: 0.3706 - acc: 0.8386 - val_loss: 0.3916 - val_acc: 0.8379\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 35s - loss: 0.3688 - acc: 0.8382 - val_loss: 0.3752 - val_acc: 0.8417\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 35s - loss: 0.3625 - acc: 0.8404 - val_loss: 0.3698 - val_acc: 0.8432\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 35s - loss: 0.3523 - acc: 0.8439 - val_loss: 0.3801 - val_acc: 0.8333\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 35s - loss: 0.3535 - acc: 0.8494 - val_loss: 0.3774 - val_acc: 0.8349\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 35s - loss: 0.3460 - acc: 0.8521 - val_loss: 0.3682 - val_acc: 0.8349\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 35s - loss: 0.3456 - acc: 0.8519 - val_loss: 0.4141 - val_acc: 0.8115\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 35s - loss: 0.3446 - acc: 0.8493 - val_loss: 0.3849 - val_acc: 0.8394\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 35s - loss: 0.3435 - acc: 0.8522 - val_loss: 0.3672 - val_acc: 0.8415\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 35s - loss: 0.3472 - acc: 0.8489 - val_loss: 0.3729 - val_acc: 0.8450\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 35s - loss: 0.3388 - acc: 0.8515 - val_loss: 0.3782 - val_acc: 0.8304\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 35s - loss: 0.3306 - acc: 0.8559 - val_loss: 0.3639 - val_acc: 0.8410\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 35s - loss: 0.3292 - acc: 0.8621 - val_loss: 0.3588 - val_acc: 0.8384\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 36s - loss: 0.3267 - acc: 0.8579 - val_loss: 0.3499 - val_acc: 0.8450\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 35s - loss: 0.3127 - acc: 0.8676 - val_loss: 0.3928 - val_acc: 0.8242\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 36s - loss: 0.3240 - acc: 0.8584 - val_loss: 0.3798 - val_acc: 0.8303\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 35s - loss: 0.3149 - acc: 0.8670 - val_loss: 0.3475 - val_acc: 0.8526\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 35s - loss: 0.3122 - acc: 0.8630 - val_loss: 0.3509 - val_acc: 0.8481\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 35s - loss: 0.3155 - acc: 0.8654 - val_loss: 0.3666 - val_acc: 0.8384\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 35s - loss: 0.3160 - acc: 0.8650 - val_loss: 0.3519 - val_acc: 0.8455\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 35s - loss: 0.3099 - acc: 0.8668 - val_loss: 0.3611 - val_acc: 0.8445\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 35s - loss: 0.3032 - acc: 0.8686 - val_loss: 0.3370 - val_acc: 0.8555\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 35s - loss: 0.2958 - acc: 0.8738 - val_loss: 0.3509 - val_acc: 0.8455\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 36s - loss: 0.2972 - acc: 0.8734 - val_loss: 0.3519 - val_acc: 0.8481\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 35s - loss: 0.2961 - acc: 0.8740 - val_loss: 0.3298 - val_acc: 0.8567\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 35s - loss: 0.2955 - acc: 0.8769 - val_loss: 0.3430 - val_acc: 0.8521\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 35s - loss: 0.2828 - acc: 0.8832 - val_loss: 0.3686 - val_acc: 0.8338\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 35s - loss: 0.2842 - acc: 0.8818 - val_loss: 0.3521 - val_acc: 0.8460\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 35s - loss: 0.2812 - acc: 0.8842 - val_loss: 0.3536 - val_acc: 0.8450\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 35s - loss: 0.2867 - acc: 0.8766 - val_loss: 0.3194 - val_acc: 0.8669\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 36s - loss: 0.2829 - acc: 0.8800 - val_loss: 0.3380 - val_acc: 0.8476\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 35s - loss: 0.2817 - acc: 0.8812 - val_loss: 0.3325 - val_acc: 0.8603\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 35s - loss: 0.2719 - acc: 0.8826 - val_loss: 0.3324 - val_acc: 0.8633\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 35s - loss: 0.2707 - acc: 0.8869 - val_loss: 0.3330 - val_acc: 0.8598\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 35s - loss: 0.2686 - acc: 0.8862 - val_loss: 0.3233 - val_acc: 0.8577\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 35s - loss: 0.2725 - acc: 0.8848 - val_loss: 0.3318 - val_acc: 0.8603\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 35s - loss: 0.2665 - acc: 0.8918 - val_loss: 0.3334 - val_acc: 0.8435\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 35s - loss: 0.2746 - acc: 0.8809 - val_loss: 0.3230 - val_acc: 0.8582\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 35s - loss: 0.2626 - acc: 0.8885 - val_loss: 0.3131 - val_acc: 0.8694\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 35s - loss: 0.2695 - acc: 0.8854 - val_loss: 0.2961 - val_acc: 0.8720\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 36s - loss: 0.2480 - acc: 0.8971 - val_loss: 0.3213 - val_acc: 0.8633\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 35s - loss: 0.2535 - acc: 0.8951 - val_loss: 0.3159 - val_acc: 0.8577\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 36s - loss: 0.2648 - acc: 0.8875 - val_loss: 0.3496 - val_acc: 0.8333\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 37s - loss: 0.2616 - acc: 0.8910 - val_loss: 0.3141 - val_acc: 0.8679\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 38s - loss: 0.2435 - acc: 0.8971 - val_loss: 0.3177 - val_acc: 0.8598\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 37s - loss: 0.2485 - acc: 0.8957 - val_loss: 0.3247 - val_acc: 0.8567\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 36s - loss: 0.2510 - acc: 0.8899 - val_loss: 0.3141 - val_acc: 0.8664\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 37s - loss: 0.2533 - acc: 0.8934 - val_loss: 0.3630 - val_acc: 0.8318\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 36s - loss: 0.2531 - acc: 0.8982 - val_loss: 0.3169 - val_acc: 0.8699\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 36s - loss: 0.2457 - acc: 0.8979 - val_loss: 0.3222 - val_acc: 0.8765\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 36s - loss: 0.2496 - acc: 0.8947 - val_loss: 0.3213 - val_acc: 0.8613\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 36s - loss: 0.2418 - acc: 0.8978 - val_loss: 0.3215 - val_acc: 0.8694\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 36s - loss: 0.2436 - acc: 0.8978 - val_loss: 0.3177 - val_acc: 0.8612\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 36s - loss: 0.2426 - acc: 0.8979 - val_loss: 0.3496 - val_acc: 0.8458\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 36s - loss: 0.2456 - acc: 0.8966 - val_loss: 0.3166 - val_acc: 0.8591\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 35s - loss: 0.2366 - acc: 0.9054 - val_loss: 0.3019 - val_acc: 0.8765\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 35s - loss: 0.2399 - acc: 0.9030 - val_loss: 0.3226 - val_acc: 0.8618\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 35s - loss: 0.2311 - acc: 0.9017 - val_loss: 0.3153 - val_acc: 0.8618\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 36s - loss: 0.2268 - acc: 0.9060 - val_loss: 0.2987 - val_acc: 0.8775\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 35s - loss: 0.2362 - acc: 0.9000 - val_loss: 0.3331 - val_acc: 0.8586\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 36s - loss: 0.2284 - acc: 0.9049 - val_loss: 0.3237 - val_acc: 0.8664\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 35s - loss: 0.2382 - acc: 0.9011 - val_loss: 0.3123 - val_acc: 0.8669\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 35s - loss: 0.2239 - acc: 0.9069 - val_loss: 0.3280 - val_acc: 0.8587\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 36s - loss: 0.2289 - acc: 0.9064 - val_loss: 0.3013 - val_acc: 0.8689\n"
     ]
    }
   ],
   "source": [
    "model=run_training(batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.8628 - val_loss: 0.3107 - val_acc: 0.8669\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making new predictions (single prediction)\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read image\n",
    "file_name='''/home/cloudera/courses/2017Aug_udemy_DeepLearningAZ/Deep_Learning_AZ/Volume1_Supervised_Deep_Learning/Part2_Convolutional_Neural_Network_CNN/Section8_Building_a_CNN/dataset/single_prediction/cat_or_dog_2.jpg'''\n",
    "test_image=image.load_img(file_name, target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAd+UlEQVR4nJ15d3Rdx3nnzNx+37uv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\ndWJU/PGmkloJRxRJCvw/Sdv0n5qgvFUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F930C07DED0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image to array to get 3D array as our input layer\n",
    "test_image=image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction inputs take inputs in batches. \n",
    "#Thus there shoud be 04 dimensions to the input, including dimension to store batch information\n",
    "#input expects this new dimension as the first index, axis=0\n",
    "test_image=np.expand_dims(test_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-dc11608986d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# does 1 corresponds to cat or dog?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "# does 1 corresponds to cat or dog?\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0]==1:\n",
    "    print 'Dog'\n",
    "else:\n",
    "    print 'Cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
